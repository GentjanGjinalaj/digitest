{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainCompanySeoFileProcessing():\n",
    "\n",
    "    main_company_file = 'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\test1.csv'\n",
    "\n",
    "    df=pd.read_csv(main_company_file)\n",
    "\n",
    "    # Create a boolean mask to identify rows to delete\n",
    "    #mask = df['Website Data Type'].isin(['Website Panel', 'Competitors Panel', 'Marketing Channel Distribution Panel', 'Keywords Panel','Category Name','First Competitor','Second Competitor','Third Competitor','Fourth Competitor','Fifth Competitor'])\n",
    "\n",
    "    # Use the boolean mask to select the rows and columns you want to modify\n",
    "    #df.loc[mask, 'Website Data Type':'Website Data'] = None\n",
    "\n",
    "    web_rows_to_delete = ['Website Panel', 'Company Name', 'Competitors Panel', 'Marketing Channel Distribution Panel', 'Keywords Panel','Category Name','First Competitor','Second Competitor','Third Competitor','Fourth Competitor','Fifth Competitor']\n",
    "    # Delete the rows\n",
    "    df.loc[df['Website Data Type'].isin(web_rows_to_delete), 'Website Data Type':'Website Data'] = np.nan\n",
    "\n",
    "    #df['Website Data'] = df['Website Data'].apply(lambda x: float(x.replace('%', '')) / 100 if '%' in str(x) else x)\n",
    "\n",
    "    # Function to process strings\n",
    "    def process_string(x):\n",
    "        str_x = str(x)\n",
    "        # Check if x is a percentage\n",
    "        if '%' in str_x:\n",
    "            return float(str_x.replace('%', '')) / 100\n",
    "        # Check if x starts with a number and is in 'K' or 'M' format\n",
    "        elif str_x[0].isdigit():\n",
    "            if 'K' in str_x:\n",
    "                return float(str_x.replace('K', '')) * 1_000\n",
    "            elif 'M' in str_x:\n",
    "                return float(str_x.replace('M', '')) * 1_000_000\n",
    "            elif ':' in str_x:  # Check if x is in 'HH:MM:SS' or 'MM:SS' format\n",
    "                time_parts = list(map(int, str_x.split(':')))\n",
    "                if len(time_parts) == 3:  # 'HH:MM:SS' format\n",
    "                    hours, minutes, seconds = time_parts\n",
    "                    return float(hours * 3600 + minutes * 60 + seconds)\n",
    "                elif len(time_parts) == 2:  # 'MM:SS' format\n",
    "                    minutes, seconds = time_parts\n",
    "                    return float(minutes * 60 + seconds)\n",
    "            else:  # Convert other numeric strings to float\n",
    "                return float(str_x)\n",
    "        # If x is neither a percentage nor in 'K' or 'M' format or a time, leave it as it is\n",
    "        return x\n",
    "\n",
    "    # Apply the function to each value in the 'Website Data' column\n",
    "    df['Website Data'] = df['Website Data'].apply(process_string)\n",
    "\n",
    "    # Function to convert numbers to float\n",
    "    def convert_to_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "\n",
    "    # Apply the function to each value in the 'SemRush API Data' column\n",
    "    #df['SemRush API Data'] = df['SemRush API Data'].apply(convert_to_float)\n",
    "\n",
    "    # Identify the rows you want to delete\n",
    "    rows_to_delete = ['Database', 'Domain', 'Date']  # Replace these with the names of the rows you want to delete\n",
    "\n",
    "    # Delete the rows\n",
    "    df.loc[df['SemRush API Data Type'].isin(rows_to_delete), 'SemRush API Data Type':'SemRush API Data'] = np.nan\n",
    "    # Split the DataFrame into two\n",
    "    mainCompanyWebDataDF = df[['Website Data Type', 'Website Data']].copy()\n",
    "    mainCompanySemRushDF = df[['SemRush API Data Type', 'SemRush API Data']].copy()\n",
    "    # Drop rows where all values are missing\n",
    "    mainCompanyWebDataDF.dropna(how='all', inplace=True)\n",
    "    mainCompanySemRushDF.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Append the second DataFrame to the first\n",
    "    #df_final = df1.append(df2, ignore_index=True)\n",
    "\n",
    "    df.to_csv('normalMainCompany.csv',index=False)\n",
    "    mainCompanyWebDataDF.to_csv('WebDataMainCompany.csv',index=False)\n",
    "    mainCompanySemRushDF.to_csv('semRushDataMainCompany.csv',index=False)\n",
    "    #print(df)\n",
    "\n",
    "    # Rename the columns in the second DataFrame\n",
    "    mainCompanySemRushDF.columns = ['Website Data Type', 'Website Data']\n",
    "\n",
    "\n",
    "    # Append the second DataFrame to the first\n",
    "\n",
    "    df_final = pd.concat([mainCompanyWebDataDF, mainCompanySemRushDF], ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame based on the 'Website Data Type' column\n",
    "    df_final = df_final.sort_values('Website Data Type')\n",
    "    df_final.to_csv('allDataMainCompany.csv',index=False)\n",
    "\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        #print(df)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitorsSeoFileProcessing():\n",
    "\n",
    "    competitor_files = ['C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\seoCompetitor_1.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\seoCompetitor_2.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\seoCompetitor_3.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\seoCompetitor_4.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\seoCompetitor_5.csv']\n",
    "\n",
    "    # Function to process strings\n",
    "    def process_string(x):\n",
    "        str_x = str(x)\n",
    "        # Check if x is a percentage\n",
    "        if '%' in str_x:\n",
    "            return float(str_x.replace('%', '')) / 100\n",
    "        # Check if x starts with a number and is in 'K' or 'M' format\n",
    "        elif str_x[0].isdigit():\n",
    "            if 'K' in str_x:\n",
    "                return float(str_x.replace('K', '')) * 1_000\n",
    "            elif 'M' in str_x:\n",
    "                return float(str_x.replace('M', '')) * 1_000_000\n",
    "            elif ':' in str_x:  # Check if x is in 'HH:MM:SS' or 'MM:SS' format\n",
    "                time_parts = list(map(int, str_x.split(':')))\n",
    "                if len(time_parts) == 3:  # 'HH:MM:SS' format\n",
    "                    hours, minutes, seconds = time_parts\n",
    "                    return float(hours * 3600 + minutes * 60 + seconds)\n",
    "                elif len(time_parts) == 2:  # 'MM:SS' format\n",
    "                    minutes, seconds = time_parts\n",
    "                    return float(minutes * 60 + seconds)\n",
    "            else:  # Convert other numeric strings to float\n",
    "                return float(str_x)\n",
    "        # If x is neither a percentage nor in 'K' or 'M' format or a time, leave it as it is\n",
    "        return x\n",
    "\n",
    "    # Function to convert numbers to float\n",
    "    def convert_to_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "\n",
    "\n",
    "    # Create an empty list to store the final DataFrames\n",
    "    final_dfs = []\n",
    "    for i, file in enumerate(competitor_files, 1):  # 'i' starts from 1\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Create a boolean mask to identify rows to delete\n",
    "        #mask = df['Website Data Type'].isin(['Website Panel', 'Competitors Panel', 'Marketing Channel Distribution Panel', 'Keywords Panel','Category Name','First Competitor','Second Competitor','Third Competitor','Fourth Competitor','Fifth Competitor'])\n",
    "\n",
    "        # Use the boolean mask to select the rows and columns you want to modify\n",
    "        #df.loc[mask, 'Website Data Type':'Website Data'] = None\n",
    "\n",
    "        web_rows_to_delete = ['Website Panel','Category Name', 'Company Name',\n",
    "                            'Keywords Panel: Competitor_1','Marketing Channel Distribution Panel: Competitor_1',\n",
    "                            'Keywords Panel: Competitor_2','Marketing Channel Distribution Panel: Competitor_2',\n",
    "                            'Keywords Panel: Competitor_3','Marketing Channel Distribution Panel: Competitor_3',\n",
    "                            'Keywords Panel: Competitor_4','Marketing Channel Distribution Panel: Competitor_4',\n",
    "                            'Keywords Panel: Competitor_5','Marketing Channel Distribution Panel: Competitor_5']\n",
    "        # Delete the rows\n",
    "        df.loc[df['Website Data Type'].isin(web_rows_to_delete), 'Website Data Type':'Website Data'] = np.nan\n",
    "\n",
    "        #df['Website Data'] = df['Website Data'].apply(lambda x: float(x.replace('%', '')) / 100 if '%' in str(x) else x)\n",
    "\n",
    "\n",
    "        # Apply the function to each value in the 'Website Data' column\n",
    "        df['Website Data'] = df['Website Data'].apply(process_string)\n",
    "\n",
    "        # Apply the function to each value in the 'SemRush API Data' column\n",
    "        df[f'SemRush API Data: Competitor_{i}'] = df[f'SemRush API Data: Competitor_{i}'].apply(convert_to_float)\n",
    "\n",
    "        # Identify the rows you want to delete\n",
    "        rows_to_delete = ['Database', 'Domain', 'Date']  # Replace these with the names of the rows you want to delete\n",
    "\n",
    "        # Delete the rows\n",
    "        df.loc[df[f'SemRush API Data Type: Competitor_{i}'].isin(rows_to_delete), f'SemRush API Data Type: Competitor_{i}':f'SemRush API Data: Competitor_{i}'] = np.nan\n",
    "        # Split the DataFrame into two\n",
    "        competitorWebDataDF = df[['Website Data Type', 'Website Data']].copy()\n",
    "        competitorSemRushDF = df[[f'SemRush API Data Type: Competitor_{i}', f'SemRush API Data: Competitor_{i}']].copy()\n",
    "        # Drop rows where all values are missing\n",
    "        competitorWebDataDF.dropna(how='all', inplace=True)\n",
    "        competitorSemRushDF.dropna(how='all', inplace=True)\n",
    "\n",
    "        # Append the second DataFrame to the first\n",
    "        #df_final = df1.append(df2, ignore_index=True)\n",
    "\n",
    "        df.to_csv(f'normalCompetitor{i}.csv',index=False)\n",
    "        competitorWebDataDF.to_csv(f'webDataCompetitor_{i}.csv',index=False)\n",
    "        competitorSemRushDF.to_csv(f'semRushDataCompetitor_{i}.csv',index=False)\n",
    "        #print(df)\n",
    "\n",
    "        # Rename the columns in the second DataFrame\n",
    "        competitorSemRushDF.columns = ['Website Data Type', 'Website Data']\n",
    "\n",
    "\n",
    "        # Append the second DataFrame to the first\n",
    "\n",
    "        df_final = pd.concat([competitorWebDataDF, competitorSemRushDF], ignore_index=True)\n",
    "\n",
    "        # Sort the DataFrame based on the 'Website Data Type' column\n",
    "        df_final = df_final.sort_values('Website Data Type')\n",
    "        df_final.to_csv(f'allDataCompetitor_{i}.csv',index=False)\n",
    "\n",
    "        # Append the final DataFrame for this iteration to the list\n",
    "        final_dfs.append(df_final)\n",
    "\n",
    "        #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            #print(df)\n",
    "    # Return the list of final DataFrames\n",
    "    return final_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = mainCompanySeoFileProcessing()\n",
    "final_dataframes = competitorsSeoFileProcessing()\n",
    "df_comp1 = final_dataframes[0]\n",
    "df_comp2 = final_dataframes[1]\n",
    "df_comp3 = final_dataframes[2]\n",
    "df_comp4 = final_dataframes[3]\n",
    "df_comp5 = final_dataframes[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
