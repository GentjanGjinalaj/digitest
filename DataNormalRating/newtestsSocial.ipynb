{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainCompanySocialMediaFileProcessing():\n",
    "    socialMediaFile = 'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\test.csv'\n",
    "\n",
    "    df=pd.read_csv(socialMediaFile)\n",
    "    df.replace('Not Available', np.nan, inplace=True)\n",
    "\n",
    "    # Function to process strings\n",
    "    def process_string(x):\n",
    "        str_x = str(x)\n",
    "        # Check if x is a percentage\n",
    "        if '%' in str_x:\n",
    "            return float(str_x.replace('%', '')) / 100\n",
    "        # Check if x starts with a number and is in 'K' or 'M' format\n",
    "        elif str_x[0].isdigit():\n",
    "            if 'K' in str_x:\n",
    "                return float(str_x.replace('K', '')) * 1_000\n",
    "            elif 'M' in str_x:\n",
    "                return float(str_x.replace('M', '')) * 1_000_000\n",
    "            elif ':' in str_x:  # Check if x is in 'HH:MM:SS' or 'MM:SS' format\n",
    "                time_parts = list(map(int, str_x.split(':')))\n",
    "                if len(time_parts) == 3:  # 'HH:MM:SS' format\n",
    "                    hours, minutes, seconds = time_parts\n",
    "                    return float(hours * 3600 + minutes * 60 + seconds)\n",
    "                elif len(time_parts) == 2:  # 'MM:SS' format\n",
    "                    minutes, seconds = time_parts\n",
    "                    return float(minutes * 60 + seconds)\n",
    "            else:  # Convert other numeric strings to float\n",
    "                return float(str_x)\n",
    "        # If x is neither a percentage nor in 'K' or 'M' format or a time, leave it as it is\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    # Specify columns to drop\n",
    "    columns_to_drop = ['Social Platform Link', 'Social Platform Username', ]\n",
    "\n",
    "    # Drop the columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # First, let's melt the DataFrame to a long format\n",
    "    df_melted = df.melt(id_vars=['Social Platform Name'], var_name='Social Data Type', value_name='Social Data')\n",
    "\n",
    "    # Then, rename 'Social Platform Name' to 'Source'\n",
    "    df_melted = df_melted.rename(columns={'Social Platform Name': 'Social Platform'})\n",
    "\n",
    "    # Apply the function to each value in the 'Website Data' column\n",
    "    df_melted['Social Data'] = df_melted['Social Data'].apply(process_string)\n",
    "    df_melted = df_melted[~((df_melted['Social Platform'] == 'Linkedin') & (df_melted['Social Data Type'] == 'Followers Count')  & df_melted['Social Data'].isna())]\n",
    "    df_melted = df_melted[~((df_melted['Social Platform'] == 'Facebook') & (df_melted['Social Data Type'] == 'Average Comments per 5 posts'))]\n",
    "    # Drop rows where all values are missing\n",
    "    df_melted.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Function to convert numbers to float\n",
    "    def convert_to_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "\n",
    "    # Save your processed DataFrame to a new CSV file\n",
    "    df_melted.to_csv('regularDataSocial\\\\processed_social_media_Main.csv', index=False)\n",
    "    #df.to_csv('Actual\\\\testsss\\\\DataNormalRating\\\\regularData\\\\social.csv')\n",
    "    return df_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitorsSocialMediaFileProcessing():\n",
    "    competitor_files = ['C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\socialCompetitor_1.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\socialCompetitor_2.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\socialCompetitor_3.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\socialCompetitor_4.csv',\n",
    "                        'C:\\\\Users\\\\User\\\\OneDrive - Fakulteti i Teknologjise se Informacionit\\\\Desktop\\\\Digitalized\\\\DigiScore\\\\DataML\\\\Competitors\\\\socialCompetitor_5.csv'\n",
    "                        ]\n",
    "\n",
    "\n",
    "    # Function to process strings\n",
    "    def process_string(x):\n",
    "        str_x = str(x)\n",
    "        # Check if x is a percentage\n",
    "        if '%' in str_x:\n",
    "            return float(str_x.replace('%', '')) / 100\n",
    "        # Check if x starts with a number and is in 'K' or 'M' format\n",
    "        elif str_x[0].isdigit():\n",
    "            if 'K' in str_x:\n",
    "                return float(str_x.replace('K', '')) * 1_000\n",
    "            elif 'M' in str_x:\n",
    "                return float(str_x.replace('M', '')) * 1_000_000\n",
    "            elif ':' in str_x:  # Check if x is in 'HH:MM:SS' or 'MM:SS' format\n",
    "                time_parts = list(map(int, str_x.split(':')))\n",
    "                if len(time_parts) == 3:  # 'HH:MM:SS' format\n",
    "                    hours, minutes, seconds = time_parts\n",
    "                    return float(hours * 3600 + minutes * 60 + seconds)\n",
    "                elif len(time_parts) == 2:  # 'MM:SS' format\n",
    "                    minutes, seconds = time_parts\n",
    "                    return float(minutes * 60 + seconds)\n",
    "            else:  # Convert other numeric strings to float\n",
    "                return float(str_x)\n",
    "        # If x is neither a percentage nor in 'K' or 'M' format or a time, leave it as it is\n",
    "        return x\n",
    "\n",
    "     # Create an empty list to store the final DataFrames\n",
    "    final_dfs = []\n",
    "    for i, file in enumerate(competitor_files, 1):  # 'i' starts from 1\n",
    "        df = pd.read_csv(file)\n",
    "        df.replace('Not Available', np.nan, inplace=True)\n",
    "\n",
    "        # Specify columns to drop\n",
    "        columns_to_drop = ['Social Platform Link', 'Social Platform Username']\n",
    "\n",
    "        # Drop the columns\n",
    "        df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "        # First, let's melt the DataFrame to a long format\n",
    "        df_melted = df.melt(id_vars=['Social Platform Name'], var_name='Social Data Type', value_name='Social Data')\n",
    "\n",
    "        # Then, rename 'Social Platform Name' to 'Source'\n",
    "        df_melted = df_melted.rename(columns={'Social Platform Name': 'Social Platform'})\n",
    "        # Apply the function to each value in the 'Website Data' column\n",
    "        df_melted['Social Data'] = df_melted['Social Data'].apply(process_string)\n",
    "        df_melted = df_melted[~((df_melted['Social Platform'] == 'Linkedin') & (df_melted['Social Data Type'] == 'Followers Count')  & df_melted['Social Data'].isna())]\n",
    "        df_melted = df_melted[~((df_melted['Social Platform'] == 'Facebook') & (df_melted['Social Data Type'] == 'Average Comments per 5 posts'))]\n",
    "        # Drop rows where all values are missing\n",
    "        df_melted.dropna(how='all', inplace=True)\n",
    "        # Append the final DataFrame for this iteration to the list\n",
    "        # Save your processed DataFrame to a new CSV file\n",
    "        df_melted.to_csv(f'regularDataSocial\\\\processed_social_media_Competior_{i}.csv', index=False)\n",
    "        final_dfs.append(df_melted)\n",
    "\n",
    "\n",
    "    #df.to_csv('Actual\\\\testsss\\\\DataNormalRating\\\\regularData\\\\social.csv')\n",
    "    return final_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_social=mainCompanySocialMediaFileProcessing()\n",
    "final_dataframes = competitorsSocialMediaFileProcessing()\n",
    "df_comp1 = final_dataframes[0]\n",
    "df_comp2 = final_dataframes[1]\n",
    "df_comp3 = final_dataframes[2]\n",
    "df_comp4 = final_dataframes[3]\n",
    "df_comp5 = final_dataframes[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "  Social Platform Social Data Type  Social Data Source\n",
      "0       Instagram  Followers Count          1.0   Main\n",
      "1        Linkedin  Followers Count          NaN   Main\n",
      "2        Facebook  Followers Count          0.0   Main\n",
      "  Social Platform           Social Data Type  Social Data Source\n",
      "0       Instagram  Average Likes per 5 posts     1.000000   Main\n",
      "1        Linkedin  Average Likes per 5 posts     0.089552   Main\n",
      "2        Facebook  Average Likes per 5 posts     0.000000   Main\n"
     ]
    }
   ],
   "source": [
    "dataframes = {}  # A dictionary to hold your new DataFrames\n",
    "\n",
    "for data_type in df_main_social['Social Data Type'].unique():\n",
    "    # Create a new DataFrame for this data_type\n",
    "    df_new = pd.DataFrame()\n",
    "\n",
    "    # Add data from the main company\n",
    "    df_main_tmp = df_main_social[df_main_social['Social Data Type'] == data_type].copy()\n",
    "    df_main_tmp['Source'] = 'Main'\n",
    "    df_new = pd.concat([df_new, df_main_tmp], ignore_index=True)\n",
    "\n",
    "    '''# Add data from each competitor\n",
    "    for i, df_comp in enumerate([df_comp1, df_comp2, df_comp3, df_comp4, df_comp5]):\n",
    "        df_comp_tmp = df_comp[df_comp['Website Data Type'] == data_type].copy()\n",
    "        df_comp_tmp['Source'] = f'Competitor {i+1}'\n",
    "        df_new = pd.concat([df_new, df_comp_tmp], ignore_index=True)'''\n",
    "\n",
    "    # Store the new DataFrame in the dictionary\n",
    "    dataframes[data_type] = df_new\n",
    "\n",
    "    scaler = MinMaxScaler()  # Initialize a scaler\n",
    "\n",
    "# Apply MinMaxScaler to each DataFrame\n",
    "for data_type, df in dataframes.items():\n",
    "    df['Social Data'] = scaler.fit_transform(df[['Social Data']])\n",
    "    dataframes[data_type] = df\n",
    "\n",
    "print(len(dataframes))\n",
    "#dataframes['SERP Features Traffic Branded']['Website Data'][2]=5.0\n",
    "#dataframes['SERP Features Traffic Branded']['Website Data'][3]=4.5\n",
    "#dataframes['SERP Features Traffic Branded']['Website Data'][4]=4.3\n",
    "print(dataframes['Followers Count'])\n",
    "print(dataframes['Average Likes per 5 posts'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
